{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W7: Automated Machine Learning\n",
    "- Contributer: Dr. Zhonghua Zheng, Yuan Sun\n",
    "- Course Unit: Earth and Environmental Data Science (EART60702)\n",
    "- Last modified date: 9 March, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intended Learning Outcomes (ILOs)\n",
    "- Learn the workflow a AutoML\n",
    "- Train and test a ML model, check the training logs\n",
    "- Learn to setup a time budget for AutoML\n",
    "- Learn the difference in resampling strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please download the data here: https://www.dropbox.com/scl/fi/azzx0olpeyx45rixlsgdn/project_1.csv?rlkey=b4fj8cnmc4ytyezppfbhpky3t&dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Please use bash commands to launch JupyterLab\n",
    "```bash\n",
    "# check if conda works in your local PC\n",
    "conda --version\n",
    "# load the environment that you created last week\n",
    "conda activate myenv\n",
    "# launch JupyterLab\n",
    "jupyter lab\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Please load the necessary Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install packages\n",
    "```\n",
    "conda install -c conda-forge xgboost=1.6.2, flaml=1.2.4, scikit-learn=1.0.2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda --version\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flaml import AutoML\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from flaml.automl.data import get_output_from_log\n",
    "\n",
    "print(\"FLAML version: {}\".format(AutoML.__version__))\n",
    "print(\"Numpy version: {}\".format(np.__version__))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"SKLearn version: {}\".format(sklearn.__version__))\n",
    "print(\"Seaborn version: {}\".format(sns.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NOTE: If your local environment doesn't work, please run the code below to install necessary packages in Google Colab: https://colab.research.google.com/**\n",
    "```python\n",
    "# https://saturncloud.io/blog/how-to-install-conda-package-to-google-colab/\n",
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "\n",
    "# check if condacolab works\n",
    "!conda --version\n",
    "\n",
    "# please install packages below in your condacolab\n",
    "!pip install --upgrade xarray zarr gcsfs cftime nc-time-axis climetlab\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Automated Machine Learning (40 mins)\n",
    "\n",
    "[FLAML: A Fast Library for Automated Machine Learning & Tuning](https://microsoft.github.io/FLAML/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data catalogue is stored as a CSV file. Here we read it with pandas.\n",
    "\n",
    "data_path = '~/Downloads/project_1.csv' # Change this to the path of the data file on your system\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(data_path, index_col=0, parse_dates=True).drop(columns=['lat', 'lon'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Split data for training and testing\n",
    "\n",
    "We will use the first 80% of the data for training and the last 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = int(0.8 * len(df))\n",
    "train, test = df.iloc[:train_num], df.iloc[train_num:]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============Plotting the data================\n",
    "df.plot(subplots=True, figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============exploratory data analysis================\n",
    "# =============trainning data================\n",
    "display(train.describe().T)\n",
    "display(train.info())\n",
    "\n",
    "# =============test data================\n",
    "display(test.describe().T)\n",
    "display(test.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Define the features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ls = df.columns.tolist()\n",
    "feature_ls.remove('TREFMXAV_U')\n",
    "print('The features are:', feature_ls)\n",
    "\n",
    "label = 'TREFMXAV_U'\n",
    "print('The label is:', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Train AutoML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== train model ======\n",
    "time_budget = 60  # total running time in seconds\n",
    "\n",
    "# specify the estimator list\n",
    "estimator_list = ['lgbm', 'rf', 'xgboost']\n",
    "\n",
    "# create the AutoML object\n",
    "automl = AutoML()\n",
    "\n",
    "# specify the automl settings\n",
    "automl_settings = {\n",
    "    \"time_budget\": time_budget,  # in seconds\n",
    "    \"estimator_list\":estimator_list, # estimators\n",
    "    \"metric\": 'rmse',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"log.log\"\n",
    "}\n",
    "\n",
    "# fit the model\n",
    "automl.fit(train[feature_ls], train[label], **automl_settings) #verbose=-1 for silent\n",
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: \n",
    "\n",
    "- What is the RMSE, R2, and MAE of the model on the training data?\n",
    "\n",
    "        ```python\n",
    "        # evaluate the final model performance\n",
    "        y_train = train[label]\n",
    "        y_pred = automl.predict(train[feature_ls])\n",
    "        print(\"training rmse:\", )\n",
    "        print(\"training r2:\", )\n",
    "        print(\"training mean_absolute_error:\", )\n",
    "        ```\n",
    "\n",
    "- Can we use other metrics to train the model (in automl_settings) ? If yes, which metrics can we use?\n",
    "    - [reference](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML#optimization-metric)\n",
    "    - `rmse`, `mse`, `r2`, `mape`\n",
    "- Plot the residuals of the model on the training data.\n",
    "\n",
    "        ```python\n",
    "        residual = observation - predictions\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== rmse, r2, mae of trainning data ======\n",
    "\n",
    "print('Trainning data')\n",
    "y_pred_train = automl.predict(train[feature_ls])\n",
    "rmse = mean_squared_error(train[label], y_pred_train, squared=False)\n",
    "r2 = r2_score(train[label], y_pred_train)\n",
    "mae = mean_absolute_error(train[label], y_pred_train)\n",
    "print('RMSE:', rmse)\n",
    "print('R2:', r2)\n",
    "print('MAE:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== plot the residual ======\n",
    "residual = train[label] - y_pred_train\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residual, kde=True)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Residual [K])')\n",
    "plt.title('Residual distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "with open('automl_model.pkl', 'wb') as f:\n",
    "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips:\n",
    "\n",
    "- Other method to save the model\n",
    "\n",
    "```python\n",
    "        import joblib\n",
    "        joblib.dump(automl, 'automl_model.pkl')\n",
    "        \n",
    "        # Load the model\n",
    "        automl = joblib.load('automl_model.pkl')\n",
    "```\n",
    "\n",
    "- [What's the difference?](https://medium.com/nlplanet/is-it-better-to-save-models-using-joblib-or-pickle-776722b5a095#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjkxNGZiOWIwODcxODBiYzAzMDMyODQ1MDBjNWY1NDBjNmQ0ZjVlMmYiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJhenAiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJhdWQiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJzdWIiOiIxMDU1NzI4ODU0NDcxMTcwMDA0NzgiLCJlbWFpbCI6Imp1bmppZXl1LnVvbUBnbWFpbC5jb20iLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwibmJmIjoxNzQxNjAxMzEzLCJuYW1lIjoiSnVuamllIFl1IiwicGljdHVyZSI6Imh0dHBzOi8vbGgzLmdvb2dsZXVzZXJjb250ZW50LmNvbS9hL0FDZzhvY0lHY3B6dmlZXzA0RnVJZVU0b3FNVEFhQWVKTHJHX2xmLTBPU1lPWF9Oc1d6VVV2QT1zOTYtYyIsImdpdmVuX25hbWUiOiJKdW5qaWUiLCJmYW1pbHlfbmFtZSI6Ill1IiwiaWF0IjoxNzQxNjAxNjEzLCJleHAiOjE3NDE2MDUyMTMsImp0aSI6ImQ2ODcyNjY5NTZiYjJlY2Y3MWRlNWFkOGU5YzkzOTdkNzI4MWI0MTMifQ.dV50fTIJW_rb5QYkTuhJBMYcmdZyCJ-MnU6_OznqRap2av7vYu2R_E9vZiD9HFY8rpqBOstyfTrOxtOboDQ3Rg55a8qdu0umGXYlamIOWRQO_JFToJg0Xjd6NbhUib48lPqCT8XCp95YtdaKDcubKTUbfKZPQm_uN0mdpc37IqoFc9D4dD1iZpdRPX2ZscE9WmstRwN5ZAsTpWLYGH6j0a9JEHuU7q2JkfyJy8Hqpn_yG9gHULDeSh9UnClR_QgHYn_trk1iZaHnDhoAvMY4KfY9Mo9UBjifoUPOqjLTOitZMkM4DHqSXs1avl-F7Tj2lydTfWJAw4MwrHHyDHrMtw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**check the logs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(automl.best_config_train_time)\n",
    "\n",
    "print(automl.best_iteration)\n",
    "\n",
    "print(automl.best_loss)\n",
    "\n",
    "print(automl.time_to_find_best_model)\n",
    "\n",
    "print(automl.config_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Check the learning curve from the log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = get_output_from_log(filename=automl_settings[\"log_file_name\"], time_budget=30)\n",
    "\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Wall Clock Time (s)\")\n",
    "plt.ylabel(\"RMSE [K]\")\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where=\"post\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============load model================\n",
    "automl = pickle.load(open('automl_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the final model performance\n",
    "y_test = test[label]\n",
    "y_pred = automl.predict(test[feature_ls])\n",
    "print(\"testing rmse:\", mean_squared_error(y_true=y_test, y_pred=y_pred, squared=False))\n",
    "print(\"testing r2:\", r2_score(y_true=y_test, y_pred=y_pred))\n",
    "print(\"testing mae:\", mean_absolute_error(y_true = y_test, y_pred = y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "- Plot the difference between the predicted and actual values of the test data\n",
    "- Plot the residuals of the test data\n",
    "- Compare the residuals of the test data with the residuals of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### example plotting\n",
    "\n",
    "residuals_train = train[label] - y_pred_train\n",
    "residuals_test = test[label] - y_pred\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(residuals_train, kde=True, color='blue', label='train')\n",
    "sns.histplot(residuals_test, kde=True, color='red', label='test')\n",
    "\n",
    "mean_train = residuals_train.mean()\n",
    "mean_test = residuals_test.mean()\n",
    "\n",
    "plt.axvline(mean_train, color='blue', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(mean_test, color='red', linestyle='dashed', linewidth=1)\n",
    "\n",
    "plt.text(-5, 200, f'Mean residuals: {mean_train.round(2)} [K]', rotation=0, color='blue')\n",
    "plt.text(-5, 100, f'Mean residuals: {mean_test.round(2)} [K]', rotation=0, color='red')\n",
    "\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Residual [K]')\n",
    "plt.title('Residual distribution')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**compare with random forest without auto tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RF()\n",
    "rf.fit(train[feature_ls], train[label])\n",
    "pred_rf = rf.predict(test[feature_ls])\n",
    "rmse_rf = mean_squared_error(test[label], pred_rf, squared=False)\n",
    "r2_rf = r2_score(test[label], pred_rf)\n",
    "mae_rf = mean_absolute_error(test[label], pred_rf)\n",
    "\n",
    "print('RMSE of RF:', rmse_rf)\n",
    "print('R2 of RF:', r2_rf)\n",
    "print('MAE of RF:', mae_rf)\n",
    "\n",
    "print('RMSE of FLAML:', mean_squared_error(test[label], y_pred, squared=False))\n",
    "print('R2 of FLAML:', r2_score(test[label], y_pred))\n",
    "print('MAE of FLAML:', mean_absolute_error(test[label], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== feature importance =========== \n",
    "\n",
    "# only when the model is tree-based, we can get the feature importance directly from the model\n",
    "fi = automl.model.estimator.feature_importances_\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=fi, y=feature_ls)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips:\n",
    "\n",
    "- Only when the model is **tree-based**, we can get the feature importance directly from the model.\n",
    "\n",
    "- The feature importance is not the same as the correlation between the feature and the target.\n",
    "\n",
    "- The feature importance is not the same as the coefficient in linear regression.\n",
    "\n",
    "- The feature importance is not the same as the p-value in statistical tests.\n",
    "\n",
    "- The feature importance is not the same as the mutual information between the feature and the target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8.1 other feature importance methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fist, you need to install the shap library by running:\n",
    "```bash\n",
    "! conda install -c conda-forge shap=0.39.0 -y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SHAPELY importances\n",
    "\n",
    "# =========== shapley ===========\n",
    "import shap\n",
    "\n",
    "# explain the model's predictions using SHAP\n",
    "explainer = shap.Explainer(automl.model.estimator)\n",
    "shap_values = explainer(train[feature_ls])\n",
    "\n",
    "# visualize the training set predictions\n",
    "shap.plots.beeswarm(shap_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips:\n",
    "\n",
    "- Negative SHAP values mean that the feature value is pushing the prediction lower (less than the expected value), while positive SHAP values mean that the feature value is pushing the prediction higher (more than the expected value).\n",
    "- Each point is a single sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first prediction's explanation\n",
    "shap.initjs()\n",
    "shap.plots.waterfall(shap_values[0])\n",
    "\n",
    "# E[f(X)] is the expected value of the model prediction \n",
    "#Â f(X) is the model prediction for a single sample X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qusetion:\n",
    "\n",
    "- [How to set up the time budget of AutoML?](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML/#how-to-set-time-budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== try different time budget ===========\n",
    "time_budget =  # update the time budget\n",
    "# update the automl settings with the new time budget\n",
    "automl_settings = {\n",
    "    \"time_budget\": time_budget,  # in seconds\n",
    "    \"estimator_list\":estimator_list, # estimators\n",
    "    \"metric\": 'rmse',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"log.log\"\n",
    "}\n",
    "# ====== train model ======\n",
    "\n",
    "automl.fit(train[feature_ls], train[label], **automl_settings) #verbose=-1 for silent\n",
    "print(automl.model.estimator)\n",
    "\n",
    "# ====== rmse, r2, mae ======\n",
    "print('Test data')\n",
    "y_pred = automl.predict(test[feature_ls])\n",
    "rmse = mean_squared_error(test[label], y_pred, squared=False)\n",
    "r2 = r2_score(test[label], y_pred)\n",
    "mae = mean_absolute_error(test[label], y_pred)\n",
    "print('RMSE:', rmse)      \n",
    "print('R2:', r2)\n",
    "print('MAE:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qusetion: \n",
    "\n",
    "- Use other estimators?\n",
    "\n",
    "  - [The supported estimators](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML#estimator)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== try different estimator ===========\n",
    "\n",
    "# update the automl settings \n",
    "automl_settings = {\n",
    "    \"time_budget\": time_budget,  # in seconds\n",
    "    \"estimator_list\": # Update your estimators list here\n",
    "    \"metric\": 'rmse',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"log.log\"\n",
    "}\n",
    "\n",
    "automl.fit(train[feature_ls], train[label], **automl_settings) #verbose=-1 for silent\n",
    "print(automl.model.estimator)\n",
    "\n",
    "# ====== rmse, r2, mae ======\n",
    "print('Test data')\n",
    "y_pred = automl.predict(test[feature_ls])\n",
    "rmse = mean_squared_error(test[label], y_pred, squared=False)\n",
    "r2 = r2_score(test[label], y_pred)\n",
    "mae = mean_absolute_error(test[label], y_pred)\n",
    "print('RMSE:', rmse)      \n",
    "print('R2:', r2)\n",
    "print('MAE:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "    \n",
    "- Specifiy the resampling strategy?\n",
    "    - [reference](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML#resampling-strategy)\n",
    "    - Try `houdout` and `cv` resampling strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== try resampling strategy ===========\n",
    "\n",
    "# update the automl settings \n",
    "automl_settings = {\n",
    "    \"time_budget\": time_budget,  # in seconds\n",
    "    \"estimator_list\": estimator_list, # estimators\n",
    "    \"metric\": 'rmse',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"log.log\",\n",
    "    \"cv\": , # Update the number of folds of the cross-validation\n",
    "}\n",
    "\n",
    "automl.fit(train[feature_ls], train[label], **automl_settings) #verbose=-1 for silent\n",
    "print(automl.model.estimator)\n",
    "\n",
    "# ====== rmse, r2, mae ======\n",
    "print('Test data')\n",
    "y_pred = automl.predict(test[feature_ls])\n",
    "rmse = mean_squared_error(test[label], y_pred, squared=False)\n",
    "r2 = r2_score(test[label], y_pred)\n",
    "mae = mean_absolute_error(test[label], y_pred)\n",
    "print('RMSE:', rmse)      \n",
    "print('R2:', r2)\n",
    "print('MAE:', mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anMBR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
